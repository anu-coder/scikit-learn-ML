{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9161a3f2",
   "metadata": {},
   "source": [
    "# Using numerical and categorical variables together\n",
    "\n",
    "In the previous notebooks, we showed the required preprocessing to apply\n",
    "when dealing with numerical and categorical variables. However, we decoupled\n",
    "the process to treat each type individually. In this notebook, we will show\n",
    "how to combine these preprocessing steps.\n",
    "\n",
    "We will first load the entire adult census dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b16ce220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "adult_census = pd.read_pickle('../data/adult_census.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b851d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_census = adult_census.drop(columns = 'education-num')\n",
    "\n",
    "target_name = 'class'\n",
    "target = adult_census[target_name]\n",
    "\n",
    "data = adult_census.drop(columns = [target_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c959e0e3",
   "metadata": {},
   "source": [
    "## Selection based on data types\n",
    "\n",
    "We will separate categorical and numerical variables using their data\n",
    "types to identify them, as we saw previously that `object` corresponds\n",
    "to categorical columns (strings). We make use of `make_column_selector`\n",
    "helper to select the corresponding columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e3eadd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "numerical_column_selector = selector(dtype_exclude= object)\n",
    "categorical_column_selector = selector(dtype_include=object)\n",
    "\n",
    "\n",
    "numerical_columns = numerical_column_selector(data)\n",
    "categorical_columns = categorical_column_selector(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186490f1",
   "metadata": {},
   "source": [
    "<div class=\"admonition caution alert alert-warning\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Caution!</p>\n",
    "<p class=\"last\">Here, we know that <tt class=\"docutils literal\">object</tt> data type is used to represent strings and thus\n",
    "categorical features. Be aware that this is not always the case. Sometimes\n",
    "<tt class=\"docutils literal\">object</tt> data type could contain other type of information (e.g. dates that\n",
    "were not parsed) and you should manually introspect the content of your\n",
    "dataframe to not wrongly use <tt class=\"docutils literal\">make_column_selector</tt>.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94c0396",
   "metadata": {},
   "source": [
    "## Dispatch columns to a specific processor\n",
    "\n",
    "In the previous sections, we saw that we need to treat data differently\n",
    "depending on their nature (i.e. numerical or categorical).\n",
    "\n",
    "Scikit-learn provides a `ColumnTransformer` class which will send specific\n",
    "columns to a specific transformer, making it easy to fit a single predictive\n",
    "model on a dataset that combines both kinds of variables together\n",
    "(heterogeneously typed tabular data).\n",
    "\n",
    "We first define the columns depending on their data type:\n",
    "\n",
    "* **one-hot encoding** will be applied to categorical columns. Besides, we\n",
    "  use `handle_unknown=\"ignore\"` to solve the potential issues due to rare\n",
    "  categories.\n",
    "* **numerical scaling** numerical features which will be standardized.\n",
    "\n",
    "Now, we create our `ColumnTransfomer` by specifying three values:\n",
    "the preprocessor name, the transformer, and the columns.\n",
    "First, let's create the preprocessors for the numerical and categorical\n",
    "parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af246e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "352e611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_preprocessor = OneHotEncoder(handle_unknown='ignore')\n",
    "numerical_preprocessor = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8cb450",
   "metadata": {},
   "source": [
    "Now, we create the transformer and associate each of these preprocessors\n",
    "with their respective columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af2b8e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('one-hot-encoder', categorical_preprocessor, categorical_columns),\n",
    "    ('standard-scaler', numerical_preprocessor, numerical_columns)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280d7370",
   "metadata": {},
   "source": [
    "A `ColumnTransformer` does the following:\n",
    "\n",
    "* It **splits the columns** of the original dataset based on the column names\n",
    "  or indices provided. We will obtain as many subsets as the number of\n",
    "  transformers passed into the `ColumnTransformer`.\n",
    "* It **transforms each subsets**. A specific transformer is applied to\n",
    "  each subset: it will internally call `fit_transform` or `transform`. The\n",
    "  output of this step is a set of transformed datasets.\n",
    "* It then **concatenate the transformed datasets** into a single dataset.\n",
    "\n",
    "The important thing is that `ColumnTransformer` is like any other\n",
    "scikit-learn transformer. In particular it can be combined with a classifier\n",
    "in a `Pipeline`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5e6501e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(preprocessor, LogisticRegression(max_iter=500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1afe00d",
   "metadata": {},
   "source": [
    "We can display an interactive diagram with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad684df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-6f160b6e-8147-450c-a388-5472a8267292 {color: black;background-color: white;}#sk-6f160b6e-8147-450c-a388-5472a8267292 pre{padding: 0;}#sk-6f160b6e-8147-450c-a388-5472a8267292 div.sk-toggleable {background-color: white;}#sk-6f160b6e-8147-450c-a388-5472a8267292 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}#sk-6f160b6e-8147-450c-a388-5472a8267292 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-6f160b6e-8147-450c-a388-5472a8267292 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-6f160b6e-8147-450c-a388-5472a8267292 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-6f160b6e-8147-450c-a388-5472a8267292 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-6f160b6e-8147-450c-a388-5472a8267292 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-6f160b6e-8147-450c-a388-5472a8267292 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-6f160b6e-8147-450c-a388-5472a8267292 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}#sk-6f160b6e-8147-450c-a388-5472a8267292 div.sk-estimator:hover {background-color: #d4ebff;}#sk-6f160b6e-8147-450c-a388-5472a8267292 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-6f160b6e-8147-450c-a388-5472a8267292 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-6f160b6e-8147-450c-a388-5472a8267292 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-6f160b6e-8147-450c-a388-5472a8267292 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}#sk-6f160b6e-8147-450c-a388-5472a8267292 div.sk-item {z-index: 1;}#sk-6f160b6e-8147-450c-a388-5472a8267292 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-6f160b6e-8147-450c-a388-5472a8267292 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-6f160b6e-8147-450c-a388-5472a8267292 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-6f160b6e-8147-450c-a388-5472a8267292 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-6f160b6e-8147-450c-a388-5472a8267292 div.sk-parallel-item:only-child::after {width: 0;}#sk-6f160b6e-8147-450c-a388-5472a8267292 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}#sk-6f160b6e-8147-450c-a388-5472a8267292 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-6f160b6e-8147-450c-a388-5472a8267292 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-6f160b6e-8147-450c-a388-5472a8267292 div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-6f160b6e-8147-450c-a388-5472a8267292\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"0430911f-8c52-40e0-96ec-4ae0a8a586fc\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"0430911f-8c52-40e0-96ec-4ae0a8a586fc\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('one-hot-encoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['workclass', 'education',\n",
       "                                                   'marital-status',\n",
       "                                                   'occupation', 'relationship',\n",
       "                                                   'race', 'sex',\n",
       "                                                   'native-country']),\n",
       "                                                 ('standard-scaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['age', 'capital-gain',\n",
       "                                                   'capital-loss',\n",
       "                                                   'hours-per-week'])])),\n",
       "                ('logisticregression', LogisticRegression(max_iter=500))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"8139126d-1a6a-4d13-8c7c-bcc2078dd6ca\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"8139126d-1a6a-4d13-8c7c-bcc2078dd6ca\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[('one-hot-encoder',\n",
       "                                 OneHotEncoder(handle_unknown='ignore'),\n",
       "                                 ['workclass', 'education', 'marital-status',\n",
       "                                  'occupation', 'relationship', 'race', 'sex',\n",
       "                                  'native-country']),\n",
       "                                ('standard-scaler', StandardScaler(),\n",
       "                                 ['age', 'capital-gain', 'capital-loss',\n",
       "                                  'hours-per-week'])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"24764ba5-0e06-4955-a045-b8cfc78e4e9f\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"24764ba5-0e06-4955-a045-b8cfc78e4e9f\">one-hot-encoder</label><div class=\"sk-toggleable__content\"><pre>['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"bc6b13ed-7357-450e-aaa2-8bf4aab133b6\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"bc6b13ed-7357-450e-aaa2-8bf4aab133b6\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown='ignore')</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"1f97a1c4-8844-4d78-a38c-ca64f832eaab\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"1f97a1c4-8844-4d78-a38c-ca64f832eaab\">standard-scaler</label><div class=\"sk-toggleable__content\"><pre>['age', 'capital-gain', 'capital-loss', 'hours-per-week']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"68defc5d-d46b-4f43-ba53-d6610fc251d1\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"68defc5d-d46b-4f43-ba53-d6610fc251d1\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"e3921b86-c599-409e-9204-87d6645b1d97\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"e3921b86-c599-409e-9204-87d6645b1d97\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=500)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('one-hot-encoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['workclass', 'education',\n",
       "                                                   'marital-status',\n",
       "                                                   'occupation', 'relationship',\n",
       "                                                   'race', 'sex',\n",
       "                                                   'native-country']),\n",
       "                                                 ('standard-scaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['age', 'capital-gain',\n",
       "                                                   'capital-loss',\n",
       "                                                   'hours-per-week'])])),\n",
       "                ('logisticregression', LogisticRegression(max_iter=500))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import set_config\n",
    "set_config(display = 'diagram')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49431880",
   "metadata": {},
   "source": [
    "The final model is more complex than the previous models but still follows\n",
    "the same API (the same set of methods that can be called by the user):\n",
    "\n",
    "- the `fit` method is called to preprocess the data and then train the\n",
    "  classifier of the preprocessed data;\n",
    "- the `predict` method makes predictions on new data;\n",
    "- the `score` method is used to predict on the test data and compare the\n",
    "  predictions to the expected test labels to compute the accuracy.\n",
    "\n",
    "Let's start by splitting our data into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6750eee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be0ed54",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"admonition caution alert alert-warning\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Caution!</p>\n",
    "<p class=\"last\">Be aware that we use <tt class=\"docutils literal\">train_test_split</tt> here for didactic purposes, to show\n",
    "the scikit-learn API.</p>\n",
    "</div>\n",
    "\n",
    "Now, we can train the model on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df2d4ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c94ae8",
   "metadata": {},
   "source": [
    "Then, we can send the raw dataset straight to the pipeline. Indeed, we do not\n",
    "need to make any manual preprocessing (calling the `transform` or\n",
    "`fit_transform` methods) as it will be handled when calling the `predict`\n",
    "method. As an example, we predict on the five first samples from the test\n",
    "set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1da636bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7762</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23881</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Other</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30507</th>\n",
       "      <td>43</td>\n",
       "      <td>14344</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28911</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19484</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  capital-gain  capital-loss  hours-per-week workclass   education  \\\n",
       "7762    56             0             0              40   Private     HS-grad   \n",
       "23881   25             0             0              40   Private     HS-grad   \n",
       "30507   43         14344             0              40   Private   Bachelors   \n",
       "28911   32             0             0              40   Private     HS-grad   \n",
       "19484   39             0             0              30   Private   Bachelors   \n",
       "\n",
       "            marital-status         occupation    relationship    race  \\\n",
       "7762              Divorced      Other-service       Unmarried   White   \n",
       "23881   Married-civ-spouse   Transport-moving       Own-child   Other   \n",
       "30507             Divorced     Prof-specialty   Not-in-family   White   \n",
       "28911   Married-civ-spouse   Transport-moving         Husband   White   \n",
       "19484   Married-civ-spouse              Sales            Wife   White   \n",
       "\n",
       "           sex  native-country  \n",
       "7762    Female   United-States  \n",
       "23881     Male   United-States  \n",
       "30507   Female   United-States  \n",
       "28911     Male   United-States  \n",
       "19484   Female   United-States  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53d2f0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' <=50K', ' >50K', ' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(data_test)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d00669b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7762      <=50K\n",
       "23881     <=50K\n",
       "30507      >50K\n",
       "28911     <=50K\n",
       "19484     <=50K\n",
       "Name: class, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519a0cad",
   "metadata": {},
   "source": [
    "To get directly the accuracy score, we need to call the `score` method. Let's\n",
    "compute the accuracy score on the entire test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "283ce71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8575874211776268"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(data_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63c2aa3",
   "metadata": {},
   "source": [
    "## Evaluation of the model with cross-validation\n",
    "\n",
    "As previously stated, a predictive model should be evaluated by\n",
    "cross-validation. Our model is usable with the cross-validation tools of\n",
    "scikit-learn as any other predictors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e897ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([2.08371925, 2.30369544, 2.09225845, 2.16638732, 2.09557629]),\n",
       " 'score_time': array([0.10800147, 0.07232356, 0.07397676, 0.07422066, 0.07290554]),\n",
       " 'test_score': array([0.8512642 , 0.8498311 , 0.84756347, 0.8523751 , 0.85513923])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cv_results = cross_validate(model, data, target, cv = 5)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d6ffaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean cross-validation accuracy is: 0.851 +/- 0.003\n"
     ]
    }
   ],
   "source": [
    "scores = cv_results['test_score']\n",
    "print(\"The mean cross-validation accuracy is: \"\n",
    "      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ef4743",
   "metadata": {},
   "source": [
    "The compound model has a higher predictive accuracy than the two models that\n",
    "used numerical and categorical variables in isolation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b788a14e",
   "metadata": {},
   "source": [
    "## Fitting a more powerful model\n",
    "\n",
    "**Linear models** are nice because they are usually cheap to train,\n",
    "**small** to deploy, **fast** to predict and give a **good baseline**.\n",
    "\n",
    "However, it is often useful to check whether more complex models such as an\n",
    "ensemble of decision trees can lead to higher predictive performance. In this\n",
    "section we will use such a model called **gradient-boosting trees** and\n",
    "evaluate its statistical performance. More precisely, the scikit-learn model\n",
    "we will use is called `HistGradientBoostingClassifier`. Note that boosting\n",
    "models will be covered in more details in a future module.\n",
    "\n",
    "For tree-based models, the handling of numerical and categorical variables is\n",
    "simpler than for linear models:\n",
    "* we do **not need to scale the numerical features**\n",
    "* using an **ordinal encoding for the categorical variables** is fine even if\n",
    "  the encoding results in an arbitrary ordering\n",
    "\n",
    "Therefore, for `HistGradientBoostingClassifier`, the preprocessing pipeline\n",
    "is slightly simpler than the one we saw earlier for the `LogisticRegression`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d109e03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "categorical_preprocessor = OrdinalEncoder(handle_unknown=\"use_encoded_value\",\n",
    "                                          unknown_value=-1)\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('categorical', categorical_preprocessor, categorical_columns)],\n",
    "    remainder=\"passthrough\")\n",
    "\n",
    "model = make_pipeline(preprocessor, HistGradientBoostingClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0e7a9a",
   "metadata": {},
   "source": [
    "Now that we created our model, we can check its statistical performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea3bdcd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = model.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83360904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8796986323806404"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(data_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06746fde",
   "metadata": {},
   "source": [
    "We can observe that we get significantly higher accuracies with the Gradient\n",
    "Boosting model. This is often what we observe whenever the dataset has a\n",
    "large number of samples and limited number of informative features (e.g. less\n",
    "than 1000) with a mix of numerical and categorical variables.\n",
    "\n",
    "This explains why Gradient Boosted Machines are very popular among\n",
    "datascience practitioners who work with tabular data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fde9182",
   "metadata": {},
   "source": [
    "In this notebook we:\n",
    "\n",
    "* used a `ColumnTransformer` to apply different preprocessing for\n",
    "  categorical and numerical variables;\n",
    "* used a pipeline to chain the `ColumnTransformer` preprocessing and\n",
    "  logistic regression fitting;\n",
    "* seen that **gradient boosting methods** can outperform **linear\n",
    "  models**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6116693b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
